{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelSummary, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import TransformerModel\n",
    "from dataset import TranslationDataModule\n",
    "from config import get_config\n",
    "\n",
    "conf = get_config()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Datamodule & Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of source sentence: 309\n",
      "Max length of target sentence: 274\n"
     ]
    }
   ],
   "source": [
    "datamodule = TranslationDataModule(conf)\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Model & Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = TransformerModel(\n",
    "    src_vocab_size=datamodule.tokenizer_src.get_vocab_size(),\n",
    "    tgt_vocab_size=datamodule.tokenizer_tgt.get_vocab_size(),\n",
    "    src_seq_len=conf[\"seq_len\"],\n",
    "    tgt_seq_len=conf[\"seq_len\"],\n",
    "    d_model=conf[\"d_model\"],\n",
    "    tokenizer_src=datamodule.tokenizer_src,\n",
    "    tokenizer_tgt=datamodule.tokenizer_tgt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelSummary(max_depth=3),\n",
    "    ModelCheckpoint(\n",
    "        dirpath=\"model_checkpoints\",\n",
    "        filename=\"tr_{epoch}\",\n",
    "        monitor=\"train_loss\",\n",
    "        mode=\"min\",\n",
    "        save_last=True,\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[1],\n",
    "    num_nodes=1,\n",
    "    max_epochs=conf[\"num_epochs\"],\n",
    "    callbacks=callbacks,\n",
    "    check_val_every_n_epoch=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /home/ravi.naik/learning/era/s15/s15lit/lightning_logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of source sentence: 309\n",
      "Max length of target sentence: 274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name                                    | Type               | Params\n",
      "--------------------------------------------------------------------------------\n",
      "0  | transformer                             | Transformer        | 75.1 M\n",
      "1  | transformer.encoder                     | Encoder            | 18.9 M\n",
      "2  | transformer.encoder.layers              | ModuleList         | 18.9 M\n",
      "3  | transformer.encoder.norm                | LayerNormalization | 2     \n",
      "4  | transformer.decoder                     | Decoder            | 25.2 M\n",
      "5  | transformer.decoder.layers              | ModuleList         | 25.2 M\n",
      "6  | transformer.decoder.norm                | LayerNormalization | 2     \n",
      "7  | transformer.src_embed                   | InputEmbeddings    | 8.0 M \n",
      "8  | transformer.src_embed.embedding         | Embedding          | 8.0 M \n",
      "9  | transformer.tgt_embed                   | InputEmbeddings    | 11.5 M\n",
      "10 | transformer.tgt_embed.embedding         | Embedding          | 11.5 M\n",
      "11 | transformer.src_pos                     | PositionalEncoding | 0     \n",
      "12 | transformer.src_pos.dropout             | Dropout            | 0     \n",
      "13 | transformer.tgt_pos                     | PositionalEncoding | 0     \n",
      "14 | transformer.tgt_pos.dropout             | Dropout            | 0     \n",
      "15 | transformer.projection_layer            | ProjectionLayer    | 11.5 M\n",
      "16 | transformer.projection_layer.projection | Linear             | 11.5 M\n",
      "17 | loss_fn                                 | CrossEntropyLoss   | 0     \n",
      "18 | cer_metric                              | CharErrorRate      | 0     \n",
      "19 | wer_metric                              | WordErrorRate      | 0     \n",
      "20 | bleu_metric                             | BLEUScore          | 0     \n",
      "--------------------------------------------------------------------------------\n",
      "75.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "75.1 M    Total params\n",
      "300.532   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbf2dc7300f41e3815689be6d44eaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, datamodule=datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
